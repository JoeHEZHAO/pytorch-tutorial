{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from lungDataLoader import lung424\n",
    "\n",
    "class UNET(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(UNET, self).__init__()\n",
    "            #conv block 1\n",
    "            self.conv1_1 = nn.Conv2d(3, 32, 3, padding=1, stride=1, dilation=1)\n",
    "            self.conv1_2 = nn.Conv2d(32, 32, 3, padding=1, stride=1, dilation=1)\n",
    "            #conv block 2\n",
    "            self.conv2_1 = nn.Conv2d(32, 64, 3, padding=1, stride=1, dilation=1)\n",
    "            self.conv2_2 = nn.Conv2d(64, 64, 3, padding=1, stride=1, dilation=1)\n",
    "            #conv block 3\n",
    "            self.conv3_1 = nn.Conv2d(64, 128, 3, padding=1, stride=1, dilation=1)\n",
    "            self.conv3_2 = nn.Conv2d(128, 128, 3, padding=1, stride=1, dilation=1)\n",
    "            #conv block 4\n",
    "            self.conv4_1 = nn.Conv2d(128, 256, 3, padding=1, stride=1, dilation=1)\n",
    "            self.conv4_2 = nn.Conv2d(256, 256, 3, padding=1, stride=1, dilation=1)\n",
    "            #deepeast conv block\n",
    "            self.conv5_1 = nn.Conv2d(256, 512, 3, padding=1, stride=1, dilation=1)\n",
    "            self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1, stride=1, dilation=1)\n",
    "            #reserver conv block0\n",
    "            self.deconv5_1 = nn.Conv2d(512, 256, 1, padding=0, stride=1, dilation=1)\n",
    "            self.deconv5_2 = nn.Conv2d(512, 256, 3, padding=1, stride=1, dilation=1)\n",
    "            self.deconv5_3 = nn.Conv2d(256, 256, 3, padding=1, stride=1, dilation=1)\n",
    "            #reverse conv block 1\n",
    "            self.deconv4_1 = nn.Conv2d(256, 128, 1, padding=0, stride=1, dilation=1)\n",
    "            self.deconv4_2 = nn.Conv2d(256, 128, 3, padding=1, stride=1, dilation=1)\n",
    "            self.deconv4_3 = nn.Conv2d(128, 128, 3, padding=1, stride=1, dilation=1)\n",
    "            #reverse conv block 2\n",
    "            self.deconv3_1 = nn.Conv2d(128, 64, 1, padding=0, stride=1, dilation=1)\n",
    "            self.deconv3_2 = nn.Conv2d(128, 64, 3, padding=1, stride=1, dilation=1)\n",
    "            self.deconv3_3 = nn.Conv2d(64, 64, 3, padding=1, stride=1, dilation=1)\n",
    "            #reverse conv block 3\n",
    "            self.deconv2_1 = nn.Conv2d(64, 32, 1, padding=0, stride=1, dilation=1)\n",
    "            self.deconv2_2 = nn.Conv2d(64, 32, 3, padding=1, stride=1, dilation=1)\n",
    "            self.deconv2_3 = nn.Conv2d(32, 32, 3, padding=1, stride=1, dilation=1)\n",
    "            self.deconv1 = nn.Conv2d(32, 1, 1, padding=0, stride=1, dilation=1)\n",
    "            self.upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x1 = F.relu(self.conv1_2(F.relu(self.conv1_1(x)))) # 224x224, 32\n",
    "            x2 = F.relu(self.conv2_2(F.relu(self.conv2_1(F.max_pool2d(x1, 2))))) # 112x112, 64\n",
    "            x3 = F.relu(self.conv3_2(F.relu(self.conv3_1(F.max_pool2d(x2, 2))))) # 56x56, 128\n",
    "            x4 = F.relu(self.conv4_2(F.relu(self.conv4_1(F.max_pool2d(x3, 2))))) # 28x28, 256\n",
    "            x = F.relu(self.conv5_2(F.relu(self.conv5_1(F.max_pool2d(x4, 2))))) # 14x14, 512\n",
    "            # 28x28, 256            \n",
    "            x = F.relu(self.deconv5_3(F.relu(self.deconv5_2(torch.cat([x4, self.upsample(F.relu(self.deconv5_1(x)))], dim=1))))) \n",
    "            # 56x56, 128            \n",
    "            x = F.relu(self.deconv4_3(F.relu(self.deconv4_2(torch.cat([x3, self.upsample(F.relu(self.deconv4_1(x)))], dim=1))))) \n",
    "            # 112x112, 64\n",
    "            x = F.relu(self.deconv3_3(F.relu(self.deconv3_2(torch.cat([x2, self.upsample(F.relu(self.deconv3_1(x)))], dim=1))))) \n",
    "            # 224x224, 32\n",
    "            x = F.relu(self.deconv2_3(F.relu(self.deconv2_2(torch.cat([x1, self.upsample(F.relu(self.deconv2_1(x)))], dim=1))))) \n",
    "            x = self.deconv1(x) # 224x224, 1\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape is torch.Size([5, 3, 224, 224])\n",
      "Ouput tensor shape is torch.Size([5, 1, 224, 224])\n",
      "Target tensor shape is torch.Size([5, 1, 224, 224])\n",
      "The loss is Variable containing:\n",
      " 0.1908\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the network\n",
    "unet = UNET()\n",
    "criterion = nn.MSELoss()\n",
    "loss = 0\n",
    "\n",
    "lungDataLoader = DataLoader(lung424, shuffle=True, batch_size=5)\n",
    "dataiter = iter(lungDataLoader)\n",
    "img, target = dataiter.next()\n",
    "img, target = Variable(img), Variable(target)\n",
    "\n",
    "out = unet(img)\n",
    "# out = torch.squeeze(out, dim=1)\n",
    "# target = torch.squeeze(out, dim=1)\n",
    "\n",
    "print('Input tensor shape is {}'.format(img.size()))\n",
    "print('Ouput tensor shape is {}'.format(out.size()))\n",
    "print('Target tensor shape is {}'.format(target.size()))\n",
    "\n",
    "loss = criterion(out,target)\n",
    "\n",
    "print('The loss is {}'.format(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unet = UNET()\n",
    "lungDataLoader = DataLoader(lung424, shuffle=True, batch_size=5)\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "optimizer = optim.SGD(unet.parameters(), lr, momentum)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 0 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,     1] loss: 0.199\n",
      "Number 1 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,     2] loss: 0.187\n",
      "Number 2 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,     3] loss: 0.268\n",
      "Number 3 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,     4] loss: 0.171\n",
      "Number 4 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,     5] loss: 0.226\n",
      "Number 5 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,     6] loss: 0.162\n",
      "Number 6 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,     7] loss: 0.227\n",
      "Number 7 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,     8] loss: 0.148\n",
      "Number 8 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,     9] loss: 0.142\n",
      "Number 9 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    10] loss: 0.179\n",
      "Number 10 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    11] loss: 0.204\n",
      "Number 11 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    12] loss: 0.252\n",
      "Number 12 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    13] loss: 0.205\n",
      "Number 13 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    14] loss: 0.138\n",
      "Number 14 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    15] loss: 0.132\n",
      "Number 15 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    16] loss: 0.192\n",
      "Number 16 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    17] loss: 0.156\n",
      "Number 17 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    18] loss: 0.168\n",
      "Number 18 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    19] loss: 0.134\n",
      "Number 19 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    20] loss: 0.227\n",
      "Number 20 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    21] loss: 0.221\n",
      "Number 21 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    22] loss: 0.168\n",
      "Number 22 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    23] loss: 0.236\n",
      "Number 23 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    24] loss: 0.162\n",
      "Number 24 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    25] loss: 0.220\n",
      "Number 25 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    26] loss: 0.219\n",
      "Number 26 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    27] loss: 0.120\n",
      "Number 27 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    28] loss: 0.156\n",
      "Number 28 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    29] loss: 0.213\n",
      "Number 29 batch with batch size torch.Size([5, 3, 224, 224])\n",
      "[1,    30] loss: 0.173\n",
      "Number 30 batch with batch size torch.Size([5, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "runing_loss = 0.0\n",
    "for epoch in range(25):\n",
    "    for i, data in enumerate(lungDataLoader):\n",
    "        img, target = data\n",
    "        print('Number {} batch with batch size {}'.format(i, img.size()))\n",
    "        \n",
    "        img, target = Variable(img), Variable(target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = unet(img)\n",
    "        \n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        runing_loss += loss.data[0]\n",
    "        print('[%d, %5d] loss: %.3f' % \n",
    "            (epoch + 1, i + 1, runing_loss))\n",
    "        runing_loss = 0.0\n",
    "        \n",
    "#         if i % 200 == 199:\n",
    "#             print(out)\n",
    "#             print(target)\n",
    "#             print('[%d, %5d] loss: %.3f' % \n",
    "#                 (epoch + 1, i + 1, runing_loss/200))\n",
    "#             runing_loss = 0.0\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
